#  *Modulo4* 

### *Nombres:*
1. DANIEL SANIN RAMIREZ
2. JULIANA MEDINA GUERREO
3. JESSICA VIVIANA MARTINEZ MARIN
4. ANDRES FELIPE GARCIA TURRIAGO

# 

## *Amazon Polarity Dataset - An치lisis de Sentimientos*

- *Fuente del Dataset*:
  El dataset completo est치 disponible en *Hugging Face*: https://huggingface.co/datasets/SetFit/amazon_polarity

### Descripci칩n

El *Amazon Polarity Dataset* es un conjunto de datos de clasificaci칩n de texto que contiene rese침as de productos de Amazon etiquetadas como *positivas (1)* o *negativas (0)*. 

Este dataset se utiliza com칰nmente en tareas de *an치lisis de sentimientos* en Procesamiento de Lenguaje Natural (NLP). El dataset fue extra칤do de revisiones de productos de Amazon y transformado en una tarea de clasificaci칩n binaria.

## *Caracter칤sticas del Dataset*
- *N칰mero total de rese침as utilizadas: **200* (extra칤das de train y test)
- *90% para entrenamiento* 
- *10% para prueba*

- *Etiquetas*:
  - 1: Rese침a positiva
  - 0: Rese침a negativa
- *Columnas disponibles*:
  - label: (0 = negativo, 1 = positivo)
  - title: T칤tulo de la rese침a
  - text: Cuerpo de la rese침a
  - split: Indica si pertenece a train o test

#
Para abordar este problema, existen diversos modelos de aprendizaje autom치tico que pueden entrenarse con los datos disponibles, cada uno con sus propias ventajas y desventajas.

Uno de los modelos m치s utilizados para este tipo de tarea es la *Regresi칩n Log칤stica*, la cual se emplea en problemas de clasificaci칩n binaria porque su salida es una probabilidad. Para lograr esto, utiliza la funci칩n sigmoide, que transforma la salida en un valor entre 0 y 1, lo que permite asignar una categor칤a a cada rese침a. Sus ventajas son la simplicidad y eficiencia cuando los datos son linealmente separables, es decir, cuando existe una frontera clara entre las clases. Sin embargo, su desventaja es que no maneja bien relaciones no lineales en los datos, lo que puede afectar su desempe침o si las rese침as contienen patrones m치s complejos.

Otra opci칩n adecuada para el an치lisis de sentimientos es el modelo de *M치quinas de Soporte Vectorial (SVM)*, que encuentra un hiperplano 칩ptimo para separar las clases en el espacio de caracter칤sticas. Lo interesante de este modelo es que puede utilizar diferentes n칰cleos para adaptar la clasificaci칩n a datos no lineales, como el n칰cleo RBF (Radial Basis Function) o el polinomial. SVM es particularmente 칰til en el procesamiento de textos, ya que funciona bien cuando se combinan con t칠cnicas como TF-IDF para representar las palabras de las rese침as en forma num칠rica. Su principal ventaja es que logra una clasificaci칩n robusta incluso en datos complejos, pero su desventaja radica en que puede ser computacionalmente costoso, especialmente cuando el volumen de datos es grande.

Por otro lado, los *츼rboles de Decisi칩n* ofrecen un enfoque diferente, basado en la divisi칩n de los datos en ramas seg칰n ciertas condiciones en las caracter칤sticas, lo que forma una estructura similar a un 치rbol. Este modelo es especialmente 칰til porque es f치cil de interpretar, lo que permite visualizar de manera clara c칩mo se toman las decisiones en la clasificaci칩n de las rese침as. Adem치s, los 치rboles de decisi칩n pueden capturar relaciones no lineales en los datos. Sin embargo, presentan una desventaja importante: tienden a sobreajustarse si no se aplica un proceso de poda o regularizaci칩n adecuado, lo que puede afectar su capacidad de generalizaci칩n en datos nuevos.

### Metricas de Regresion logistica ###
![image](https://github.com/user-attachments/assets/ca6894e6-c9d4-4509-a55c-043543e4fba5)

### Curva de aprendizaje de Regresion logistica ###
![image](https://github.com/user-attachments/assets/1b4f934d-2538-4f02-8f56-6f649fc650e0)


### Metricas de evaluacion SVM ###
![image](https://github.com/user-attachments/assets/cfc5689a-0c82-4f12-a5a3-2ad12bc61064)

### Curva de aprendizaje de SVM ###
![image](https://github.com/user-attachments/assets/f0fcba5c-7635-4f0d-b6d6-0fbb8fd4bc3e)


### Metricas de evaluacion Arbol de decision ###
![image](https://github.com/user-attachments/assets/4bbd13fc-02db-48d3-88c7-5495e746fc38)

### Curva de aprendizaje de Arbol de decision ###
![image](https://github.com/user-attachments/assets/8b66d5c6-5af7-415f-b877-7acb991e2150)




## Conclusiones del Proyecto

La implementaci칩n de la regresi칩n log칤stica junto con la vectorizaci칩n TF-IDF ha demostrado ser una soluci칩n efectiva para la clasificaci칩n de sentimientos en el conjunto de datos de rese침as de Amazon, logrando un modelo con alta precisi칩n y capacidad de generalizaci칩n para diferenciar opiniones positivas y negativas. Sin embargo, presenta limitaciones en la detecci칩n de sarcasmo e iron칤a, lo que puede afectar la interpretaci칩n de algunas rese침as. Como bien se dijo, la regresion logisitica es un buen punto de partida, pero su variabilidad en la curva de aprendizaje sugiere que se pondr칤a mejora su generalizacion. En comparacion, la precision parece ser silimar en los tres modelos, lo que sugiere que todos estan desempe침adose de manera comparable en terminos de clasificaicon general. La limpieza y normalizaci칩n de los datos textuales, incluyendo la conversi칩n a min칰sculas, la eliminaci칩n de caracteres especiales y espacios redundantes, fueron claves para mejorar la calidad de los datos y el desempe침o del modelo. Adem치s, la integraci칩n de MLflow permiti칩 un seguimiento eficiente de los experimentos, facilitando la comparaci칩n de configuraciones y asegurando la reproducibilidad de los resultados. 

## Consideraciones a mejorar ##

- El modelo de 츼rbol de Decisi칩n entrenado con el criterio de "gini", una profundidad m치xima de 5 y una semilla aleatoria de 42 proporciona un equilibrio entre interpretabilidad y rendimiento. Sin embargo, para mejorar su desempe침o, se podr칤an probar otras configuraciones como aumentar max_depth para capturar m치s patrones complejos, cambiar el criterio a "entropy" para evaluar mejor la pureza de los nodos, y ajustar min_samples_split o min_samples_leaf para evitar el sobreajuste. Tambi칠n, t칠cnicas como la poda post-entrenamiento o el uso de modelos ensamblados como Random Forest podr칤an mejorar la generalizaci칩n del modelo.

- El modelo de Support Vector Machine (SVM) entrenado con un kernel lineal y un par치metro de regularizaci칩n 
洧냤=1.0 ofrece una buena capacidad de generalizaci칩n en datos linealmente separables. Sin embargo, para mejorar su rendimiento, se podr칤an probar otros valores de C para encontrar el mejor equilibrio entre sesgo y varianza, as칤 como utilizar kernels m치s complejos como rbf o poly en caso de que los datos no sean linealmente separables. Adem치s, la optimizaci칩n de hiperpar치metros mediante b칰squeda en cuadr칤cula (GridSearchCV) o b칰squeda aleatoria (RandomizedSearchCV) podr칤a ayudar a encontrar la configuraci칩n m치s 칩ptima del modelo.


- A pesar de los buenos resultados obtenidos, se pueden explorar t칠cnicas avanzadas como modelos basados en redes neuronales o transformers para mejorar la precisi칩n y la capacidad de generalizaci칩n, mientras que la ampliaci칩n del conjunto de datos con m치s ejemplos podr칤a reducir sesgos y aumentar la robustez del sistema.  Este enfoque es escalable y adaptable a otros dominios, como el an치lisis de opiniones en redes sociales o la detecci칩n de tendencias de mercado, convirti칠ndolo en una herramienta valiosa para diversas aplicaciones.


